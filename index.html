<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Laser Eyes AR - Three.js & MediaPipe</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #000;
            font-family: 'Courier New', Courier, monospace;
        }

        #container {
            position: relative;
            width: 100vw;
            height: 100vh;
        }

        /* The webcam video (hidden, we render it to canvas or just sit behind) 
           We will mirror it with CSS to make it feel natural */
        #input_video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); 
            z-index: 0;
        }

        /* The Three.js Canvas */
        #output_canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
            transform: scaleX(-1); /* Match video mirror */
        }

        #loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #00ff00;
            font-size: 24px;
            background: rgba(0, 0, 0, 0.8);
            padding: 20px;
            border: 1px solid #00ff00;
            border-radius: 8px;
            z-index: 10;
            text-align: center;
        }

        #controls {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 20;
        }

        button {
            background: #ff0000;
            color: white;
            border: none;
            padding: 12px 24px;
            font-size: 16px;
            font-weight: bold;
            cursor: pointer;
            border-radius: 4px;
            box-shadow: 0 0 15px #ff0000;
            text-transform: uppercase;
        }
        
        button:hover {
            background: #cc0000;
        }
        
        .hidden {
            display: none !important;
        }
    </style>
    
    <!-- MediaPipe Scripts (Global) -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
    
    <!-- Three.js as ES Module -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js"
            }
        }
    </script>
</head>
<body>

    <div id="container">
        <video id="input_video" playsinline></video>
        <canvas id="output_canvas"></canvas>
        
        <div id="loading">
            INITIALIZING SYSTEM...<br>
            <span style="font-size: 14px; color: #aaa;">(Please allow camera access)</span>
        </div>

        <div id="controls" class="hidden">
            <button id="toggleBtn">Toggle Lasers</button>
        </div>
    </div>

    <script type="module">
        import * as THREE from 'three';

        // --- Configuration ---
        const LANDMARK_IDS = {
            LEFT_EYE: 468,  // Iris center
            RIGHT_EYE: 473, // Iris center
            NOSE_TIP: 1,
            FOREHEAD: 10,
            CHIN: 152,
            LEFT_CHEEK: 234,
            RIGHT_CHEEK: 454
        };

        // --- State ---
        const state = {
            lasersEnabled: false, // Changed to false initially
            isLoaded: false
        };

        // --- DOM Elements ---
        const videoElement = document.getElementById('input_video');
        const canvasElement = document.getElementById('output_canvas');
        const loadingElement = document.getElementById('loading');
        const controlsElement = document.getElementById('controls');
        const toggleBtn = document.getElementById('toggleBtn');

        // --- Three.js Setup ---
        const scene = new THREE.Scene();
        
        // Camera setup: We use an Orthographic camera to map 1:1 with the video feed roughly
        // for easier 2D landmark overlay, but give it depth for the 3D lasers.
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 100; // Arbitrary, we will project logic based on this

        const renderer = new THREE.WebGLRenderer({ 
            canvas: canvasElement, 
            alpha: true, // Transparent background so we can see the video
            antialias: true 
        });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);

        // Handle Window Resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        // --- Laser Objects ---
        // We create a container for each eye that holds the laser beam and the glow sprite.
        // This allows us to rotate the container to point the laser.
        
        function createLaser() {
            const container = new THREE.Object3D();

            // 1. The Beam (Cylinder)
            // Cylinder geometry: radiusTop, radiusBottom, height, radialSegments
            // We pivot it at the bottom so rotation works from the eye outward
            const beamLen = 2000;
            const beamGeo = new THREE.CylinderGeometry(2, 6, beamLen, 8);
            beamGeo.translate(0, beamLen / 2, 0); // Shift so origin is at bottom
            beamGeo.rotateX(-Math.PI / 2); // Point along Z axis initially

            const beamMat = new THREE.MeshBasicMaterial({ 
                color: 0xff0000,
                transparent: true,
                opacity: 0.6,
                blending: THREE.AdditiveBlending,
                depthWrite: false
            });
            const beam = new THREE.Mesh(beamGeo, beamMat);
            container.add(beam);

            // 2. The Core (Thinner, brighter beam inside)
            const coreGeo = new THREE.CylinderGeometry(0.5, 0.5, beamLen, 8);
            coreGeo.translate(0, beamLen / 2, 0);
            coreGeo.rotateX(-Math.PI / 2);
            const coreMat = new THREE.MeshBasicMaterial({ 
                color: 0xffffff,
                transparent: true,
                opacity: 0.8,
                blending: THREE.AdditiveBlending
            });
            const core = new THREE.Mesh(coreGeo, coreMat);
            container.add(core);

            // 3. The Eye Glow (Sprite)
            const textureLoader = new THREE.TextureLoader();
            // Creating a simple procedural glow texture via canvas to avoid external assets
            const glowCanvas = document.createElement('canvas');
            glowCanvas.width = 64;
            glowCanvas.height = 64;
            const ctx = glowCanvas.getContext('2d');
            const grd = ctx.createRadialGradient(32, 32, 0, 32, 32, 32);
            grd.addColorStop(0, 'rgba(255, 255, 255, 1)');
            grd.addColorStop(0.4, 'rgba(255, 0, 0, 0.5)');
            grd.addColorStop(1, 'rgba(0, 0, 0, 0)');
            ctx.fillStyle = grd;
            ctx.fillRect(0, 0, 64, 64);
            
            const glowTex = new THREE.CanvasTexture(glowCanvas);
            const spriteMat = new THREE.SpriteMaterial({ 
                map: glowTex, 
                color: 0xff0000, 
                blending: THREE.AdditiveBlending 
            });
            const sprite = new THREE.Sprite(spriteMat);
            sprite.scale.set(20, 20, 1);
            container.add(sprite);

            scene.add(container);
            return container;
        }

        const leftLaser = createLaser();
        const rightLaser = createLaser();

        // --- MediaPipe Face Mesh Setup ---
        
        // Coordinate mapping helper
        // MediaPipe returns 0.0-1.0 coordinates. We need to map this to Three.js world units.
        // Since we are using a PerspectiveCamera at z=100 looking at z=0, we can approximate the plane.
        // A robust way is to use `vector.unproject` but simple scaling works well for visual effects overlays.
        function mapLandmarkToWorld(landmark, width, height) {
            // Center is (0,0)
            // x: 0 to 1 -> -w/2 to w/2
            // y: 0 to 1 -> h/2 to -h/2 (inverted because DOM y is down, 3D y is up)
            
            // To make the tracking tight, we calculate the visible width/height at the target Z depth.
            // For z=0 (face plane approx) and camera z=100:
            const vFOV = THREE.MathUtils.degToRad(camera.fov);
            const visibleHeight = 2 * Math.tan(vFOV / 2) * camera.position.z;
            const visibleWidth = visibleHeight * camera.aspect;

            return new THREE.Vector3(
                (landmark.x - 0.5) * visibleWidth,
                -(landmark.y - 0.5) * visibleHeight,
                -landmark.z * visibleWidth * 0.5 // Depth approximation
            );
        }

        function onResults(results) {
            if (!state.isLoaded) {
                state.isLoaded = true;
                loadingElement.classList.add('hidden');
                controlsElement.classList.remove('hidden');
            }

            // Draw video frame? 
            // Actually, the video element #input_video is playing in the background.
            // We just clear the Three.js scene and render on top.
            
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const landmarks = results.multiFaceLandmarks[0]; // Just take the first face

                // 1. Get Coordinates
                const leftEyePos = mapLandmarkToWorld(landmarks[LANDMARK_IDS.LEFT_EYE], window.innerWidth, window.innerHeight);
                const rightEyePos = mapLandmarkToWorld(landmarks[LANDMARK_IDS.RIGHT_EYE], window.innerWidth, window.innerHeight);
                
                // 2. Calculate Face Orientation (Normal)
                // We use 3 points to define the plane of the face:
                // Center of eyes (midpoint), Nose, and something else or cross product of vectors.
                // Improved method: Vector from EyeMid to Mouth (Vertical) cross Vector from EyeL to EyeR (Horizontal)
                
                const cheekL = mapLandmarkToWorld(landmarks[LANDMARK_IDS.LEFT_CHEEK]);
                const cheekR = mapLandmarkToWorld(landmarks[LANDMARK_IDS.RIGHT_CHEEK]);
                const nose = mapLandmarkToWorld(landmarks[LANDMARK_IDS.NOSE_TIP]);
                const forehead = mapLandmarkToWorld(landmarks[LANDMARK_IDS.FOREHEAD]);
                const chin = mapLandmarkToWorld(landmarks[LANDMARK_IDS.CHIN]);

                // Vector pointing "forward" out of the face
                // Simple approximation: The cross product of (RightCheek - LeftCheek) and (Forehead - Chin)
                const horizontalVec = new THREE.Vector3().subVectors(cheekR, cheekL).normalize();
                const verticalVec = new THREE.Vector3().subVectors(forehead, chin).normalize();
                
                // Normal vector (pointing out of face)
                const faceNormal = new THREE.Vector3().crossVectors(verticalVec, horizontalVec).normalize();

                // 3. Update Lasers
                if (state.lasersEnabled) {
                    leftLaser.visible = true;
                    rightLaser.visible = true;

                    leftLaser.position.copy(leftEyePos);
                    rightLaser.position.copy(rightEyePos);

                    // Point lasers along the face normal
                    // Create a target point far away along the normal
                    const targetL = leftEyePos.clone().add(faceNormal.clone().multiplyScalar(1000));
                    const targetR = rightEyePos.clone().add(faceNormal.clone().multiplyScalar(1000));

                    leftLaser.lookAt(targetL);
                    rightLaser.lookAt(targetR);
                } else {
                    leftLaser.visible = false;
                    rightLaser.visible = false;
                }

            } else {
                // No face detected
                leftLaser.visible = false;
                rightLaser.visible = false;
            }

            renderer.render(scene, camera);
        }

        // --- Initialization ---

        const faceMesh = new FaceMesh({locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
        }});

        faceMesh.setOptions({
            maxNumFaces: 1,
            refineLandmarks: true, // Important for accurate iris tracking
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        faceMesh.onResults(onResults);

        const cameraUtils = new Camera(videoElement, {
            onFrame: async () => {
                await faceMesh.send({image: videoElement});
            },
            width: 1280,
            height: 720
        });

        // Start camera
        cameraUtils.start().catch(err => {
            console.error(err);
            loadingElement.innerHTML = "Error accessing camera.<br>Please check permissions.";
            loadingElement.style.borderColor = "red";
            loadingElement.style.color = "red";
        });

        // --- UI Controls ---
        toggleBtn.addEventListener('click', () => {
            state.lasersEnabled = !state.lasersEnabled;
        });

    </script>
</body>
</html>
